# CS205 C/C++ Program Design

### Assignment 3

**Name**: 方唯可   **SID**: 22010055

#### Part 1. Analysis & Description

This assignment asked us to design a function that computes the dot product of two vectors. Then, we should test our function by using I/O (asking users' input) without crashing, measure the time of calculation for very large vectors (~200M elements each), and then try to improve the efficiency of our function to be compared with OpenBLAS *cblas_sdot()* function.

The first task is straightforward: we need to read the input, load them to our vectors, do the calculation, and print the result. A possible crashdown may occur when users enter vectors of different sizes or invalid characters such as letters, symbols, etc. The first pathology can be taken care of by keep track of the sizes of the two vectors, and report to the user that the sizes do not match. The latter can be dealt with by asking the user to enter again if an illegal character is detected by cin/scanf.

The second task asks us to measure the time (in *ms*) that the calculation takes for vectors of 200 million elements. To create a float vector with 200 M elements, I use **new** to assign a block of dynamic memory to the vector and then use `float r = static_cast<float>(rand()) / (static_cast<float>(RAND_MAX));`to assign to each element a floating-point number between 0 and 1 (for testing).

The first version of the dot product function I wrote was just brute force.

```c++
float dot(int index, float *v1, float *v2)
{
    float result;
    for (int i = 0; i < index; i++)
    {
        result += v1[i] * v2[i];
    }
    return result;
}
```

Such a function takes around **540 ms** to calculate the dot product for vectors of 200M elements. 

![1](C:\Users\colin\Desktop\1.PNG)

The third requirement asks us to improve the efficiency of our source code. After some research online, I notice an easy yet helpful method to enhance efficiency, SIMD operations. SIMD (Single Instruction Multiple Data) allows us  to access and process multiple data simultaneously. (Credit to Eric Holk https://blog.theincredibleholk.org/blog/2012/12/10/optimizing-dot-product/) In our case, we can reduce the for-loops we need and make better use of our CPU to perform dot products. (More details later) 

The dot product function spends most of its time retrieving data from the (dynamic) memory since the function does little actual and straightforward computation. Thus, the efficiency will be very much dependent on its memory access (bandwidth). Some computer architecture experts would propose to use cache to store data that might be reaccessed. But since our dot product function only accesses each element once, we are not able to improve the algorithm in this way. However, as inspired by the ATLAS library from Eric's post, I am thinking about reducing the number of loops by dividing the task into four (unrolling four times). The code should be like:

```
for (int i = 0; i < index; i+=4)
{
    dot1 += v1[i] * v2[i];
    dot2 += v1[i+1] * v2[i+1];
    dot3 += v1[i+2] * v2[i+2];
    dot4 += v1[i+3] * v2[i+3];
}
result = dot1 + dot2 + dot3 + dot4;
    return result;
```

Here, since each execution in the loop is not dependent on the others, the CPU will run the four tasks together (the order execution engine works its magic), which is basically the idea of vectorization. In our test, such operation reduces the execution time by around 200ms (**to around 326ms**, even more when **float** is used to store the **result** at the cost of precision). 

As to determine the optimal number of division of the task, I have conducted some experiments to find the most efficient one rigorously. As we can see from the table below, there is an efficiency boost when we move from 1 to 2 (almost halves), indicating that the CPU's execution engine compute the two instructions almost synchronously. The enhancement then encounters the *reducing marginal utility* stage, where it improves little with every increment of divisions (from 2 to 4). The time taken becomes longer from 4 to 5 on my PC, indicating that 4 number of divisions should be optimal on my PC.

| #of division  | 1 (ms) | 2 (ms) | 3 (ms) | 4 (ms) | 5 (ms) |
| ------------- | ------ | ------ | ------ | ------ | ------ |
| Trail 1       | 540    | 357    | 335    | 330    | 340    |
| Trial 2       | 536    | 361    | 381    | 332    | 338    |
| Trial 3       | 538    | 360    | 376    | 318    | 373    |
| Trial 4       | 578    | 364    | 335    | 320    | 335    |
| Trial 5       | 539    | 362    | 340    | 331    | 334    |
| Trial 6       | 538    | 362    | 337    | 318    | 319    |
| Trial 7       | 542    | 363    | 341    | 335    | 321    |
| Trial 8       | 537    | 364    | 334    | 321    | 326    |
| Trial 9       | 540    | 360    | 335    | 339    | 340    |
| Trial 10      | 531    | 363    | 351    | 320    | 328    |
| Average       | 541.9  | 361.6  | 346.5  | 326.4  | 335.4  |
| Std Deviation | 12.36  | 2.06   | 16.72  | 7.42   | 14.44  |

Besides, as we have discussed in class, the c++ complier has been so advanced that it can interpret our code very efficiently.  Therefore, some improvement methods proposed, such as do part of the calculation at the initialization step, actually complicate the code and have tiny improvement. Instead of focusing on how to do fancy calculations, I then sought to find ways to specify the **compiler flags**, as inspired by Eric's post. 

The first flag that might be helpful is `-funroll-loops` , as we divide the *sum* into four (*sum1 sum2 sum3 sum4*) and unroll each for-loop four times. Other GCC/G++ optimization flags that might be helpful include `-Ofast`, which inherently enables `-ffast-math` to increase the efficiency of math calculations. Also, as I am running the code on the same machine where I write the code, the flag `-march=native` , which "enables instruction specific to a given CPU architecture" (quote from Pyves on https://stackoverflow.com/questions/14492436/g-optimization-beyond-o3-ofast). However, it cautions me that if I want to run the program on a different machine, I should not use this compiler flag. All in all, if we compile the code with the above flags, it actually reaches very high efficiency and reduces the running time of the calculation to **around 90 ms**, a huge leap of efficiency. (screenshot below)

The last part of the assignment asks us to compare our calculation with OpenBLAS, one of the best linear algebra libraries at present. I encountered some hardship when building and compiling the library, but finally succeeded. I compute the dot product using OpenBLAS's function *cblas_sdot()*, and compare the time and result with my own function. The result shows that OpenBLAS library computes dot product around 10ms faster (**around 80 ms**), indicating that my function is pretty close to it regarding efficiency but still open to improvement. The OpenBLAS library also outperforms mine in terms of accuracy. Assuming the result from the OpenBLAS is accurate, the output from my dot-product function has a difference of around **0.5%**, which seems small but is a significant difference for large numbers. (Screenshot below) Using **float** to store my result proves to enhance the efficiency of my function by around **1-2 ms** but lead to a much larger different (~5%).

#### Part 2. Code

I hosted my **two source codes** (one for testing with I/O and the other for improvements and comparison with OpenBLAS) on GitHub and it can be viewed via https://github.com/ColinFang1009/sustechcpp/tree/master/assignment3 

(The vecdot.cpp code tests my function by I/O and the vecob.cpp code compares my function with OpenBLAS library).

In case of convenience, I also put the essential part of my second code here (more details at GitHub).

Efficiency improvement and comparison

```
//vector dot product calculator
//Name: Weike Fang (22010055)
#include <cblas.h>
#include <stdio.h>
#include <algorithm>
#include <iostream>
#include <iomanip>
#include <ctime>
#include <chrono>
#include <cstdlib>

using namespace std;
double dot(int index, float *v1, float *v2)
{
    double dot1;
    double dot2;
    double dot3;
    double dot4;
    double result;
    for (int i = 0; i < index; i+=4)
    {
        dot1 += v1[i] * v2[i];
        dot2 += v1[i+1] * v2[i+1];
        dot3 += v1[i+2] * v2[i+2];
        dot4 += v1[i+3] * v2[i+3];
    }
    result = dot1 + dot2 + dot3 + dot4;
    return result;
}
int main()
{
    srand(static_cast<unsigned>(time(0))); //set seed
    int n = 200000000;
    float *v1 = new float[n];
    float *v2 = new float[n];
    for (int i = 0; i < n; i++)
    {
        float r2 = static_cast<float>(rand()) / (static_cast<float>(RAND_MAX));
        float r1 = static_cast<float>(rand()) / (static_cast<float>(RAND_MAX));
        //float r1 = 1.0;
        //float r2 = 1.0;
        v1[i] = r1;
        v2[i] = r2;
    }
    float result;

    auto start = std::chrono::steady_clock::now();
    result = cblas_sdot(n, v1, 1, v2, 1);
    auto end = std::chrono::steady_clock::now();
    cout << "Using OpenBLAS lib: \n";
    cout << "The dot product is " << result << endl;
    std::cout << "Dot product calculations took "
              << std::chrono::duration_cast<std::chrono::microseconds>(end - start).count() << "mus = "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() << "ms ="
              << std::chrono::duration_cast<std::chrono::seconds>(end - start).count() << "s.\n\n";
              
    auto start2 = std::chrono::steady_clock::now();
    double result2 = dot(n, v1, v2);
    auto end2 = std::chrono::steady_clock::now();
    cout << "Using my dot-product function: \n";
    cout << "The dot product2 is " << result2 << endl;
    std::cout << "Dot product calculations took "
              << std::chrono::duration_cast<std::chrono::microseconds>(end2 - start2).count() << "mus = "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end2 - start2).count() << "ms ="
              << std::chrono::duration_cast<std::chrono::seconds>(end2 - start2).count() << "s.\n\n";
              
    delete[] v1;
    delete[] v2;
}

```



#### Part 3. Result & Verification

I/O part

Test case #1 (normal dot-product calculation for floating-point vectors):

```
Input:
v1 = 1.13 2.21 3.34 3.2 4.5 6.5 1.2 3.4
v2 = 3.2 4.34 2.3 1.2 4.3 5.56 6.67 7.0
Output:The dot product is 112.023
```

Screen-shot for case #1:

![1-1](C:\Users\colin\Desktop\1-1.PNG)

Test case #2: If illegal characters are entered, the program will ask the user to enter again until valid input is received. Then for vector2 the program repeats the same process, only storing the value when standard input is received. And then output the product

```
Input: v1 = 1 2 3 a 4
Output: There is an illegal input. Please Enter Again
Input: v1 = 1 2 3 4 5.1
Input: v2 = q w e r t
Output: There is an illegal input. Please Enter Again
Input:v2 = 1.2 2.3 3.4 4.5 5.6
Output: The dot product is 62.56
```

Screen-shot for case #2:

![Illegal_Input](C:\Users\colin\Desktop\Illegal_Input.PNG)

Test case #3: Sizes of the two vectors do not match; the program then can either rerun/calculate the dot product within the sub-vector (or like treating the remaining elements as 0). 

```
Input:
v1 = 1 2 3 4 5
v2 = 1 2 3 4
Output: The sizes of the vectors do not match
```

Screen-shot for case #3:

![size_not_match](C:\Users\colin\Desktop\size_not_match.PNG)



Efficiency improvement and Comparison with OpenBLAS

Test case #1: Brute-force function (1st version)

```
Randomize two vectors of 200 million elements (each between 0 and 1)
Output:
The dot product is 4.99996e+07
Dot product calculations took 538ms.
```

Screen-shot for case #1:

![1](C:\Users\colin\Desktop\1.PNG)

Test case #2: Improvement by dividing the task into four (compling with standard math)

```
for (int i = 0; i < index; i+=4)
{
    dot1 += v1[i] * v2[i];
    dot2 += v1[i+1] * v2[i+1];
    dot3 += v1[i+2] * v2[i+2];
    dot4 += v1[i+3] * v2[i+3];
}
result = dot1 + dot2 + dot3 + dot4;
Compile:g++ (standard math without complier flags)
Output:
The dot product is 5.00005e+07
Dot product calculations took 320ms.
```

Screen-shot for case #2:

![4div](C:\Users\colin\Desktop\4div.PNG)

Test case #3: Complie with chosen optimization flags

```
Complie:g++ -Ofast -march=native -funroll-loop
Output:
The dot product is 4.99987e+07
Dot product calculations took 86ms.
```

Screenshot for case #3:

![flag](C:\Users\colin\Desktop\flag.PNG)

Such operation proves to be much faster, and fluctuate only a little. The remaining problem is whether the calculation is accurate enough, as we don't know the correct result given two randomized  vectors. Thus, I then wish to compare my result with OpenBLAS's function to see whether the result is accurate and compare the time taken (efficiency).

Test case #4: Comparison with OpenBLAS Library. Calculate the dot product of the same two randomized vectors of 200 M elements.

```
Complie: g++ vecob.cpp -I ../include/ -L ../lib -lopenblas -Ofast -march=native -funroll-loops
Output:
Using OpenBLASlib:
Result: 4.97473e+07
Time:83ms
Using my dot-product function
Result:4.99985e+07
Time:95ms
```

Screenshot for case #4:

![compare](C:\Users\colin\Desktop\compare.PNG)

As we can see, the OpenBLAS library performs around 10 ms quicker than my function. Assuming the result from OpenBLAS is accurate, my dot-product function produces around 0.5% error/uncertainty.

#### Part 4. Difficulties & Solutions

Difficulty 1: Setting up the OpenBLAS Library. There are many tutorials online about building the OpenBLAS library, but differing in operating systems, IDE, CPU core, processor, etc. Also, the majority of the tutorials omit some steps in between that lead to more confusion.

Solution: 1. Download the openblas source file (.zip) or via git clone to a assigned directory (http://www.openblas.net/). 2. Install mysy following the instructions from https://blog.csdn.net/yangyangyang20092010/article/details/46350519 3. Build and complie (make) the OpenBLAS directory (https://github.com/xianyi/OpenBLAS/wiki/How-to-use-OpenBLAS-in-Microsoft-Visual-Studio && https://blog.csdn.net/yangyangyang20092010/article/details/45156881 (2.4-2.5)) 4.Copy the include and lib directory to where your code is. 5. Include <cblas.h> in the header file, complie with the form  *g++ xxx.cpp -I ./include/ -L ../lib -lopenblas* 6. Functions to use follows Apple-Developer's documentation about OpenBLAS (https://developer.apple.com/documentation/accelerate/1513280-cblas_sdot?language=objc)

Difficulty 2: Improving my function (brute force version)

Solution: Credit to Eric Holk's blog as inspiration. Then I test the way to divide the sum that is the most efficient (turns our to be 4!). Also, his blog informs me that fancy operations/methods such as using cache, may not help in the case of dot product, as discussed in part 1.

Difficulty 3: Improving further from SIMD

Solution: Inspired from Xavier and Daniel Lemire 's discussion (https://lemire.me/blog/2018/07/05/how-quickly-can-you-compute-the-dot-product-between-two-large-vectors/), I find that for operations like dot product on large vectors, accessing data took more time than simple calculations, which is deemed as a compute-bound. However, specifying compilier (optimization) flags proves to be effective in both Lemire's experiment and mine above. **-Ofast -march=native -funroll-loops** reduces the time to its 1/4.

Difficulty 4: Float v.s. Double

Solution: The vectors are initialized to the **float** type. I initially claim the *result* as *float*, but found that it induces a large error from the result. In order to solve this problem, I tried using the function in my last assignment with ***high precision floating-point calculation***, but then found it sacrifice a large portion of efficient. Then I tried the **double** data type, which largely reduces the error **from around 5% to 0.5%**, only at the sacrifice of around **2ms** efficiency.

![float-compare](C:\Users\colin\Desktop\float-compare.PNG)

Float-type V.S. Openblas: the efficiency becomes slightly higher, at the cost of great uncertainty.

Difficulty 5: In the I/O testing part, scan the input without knowing the size of the array. && Dealing with the problem if the two vectors have different sizes.

Solution: Add the **index1, index2** variables to keep track of the size. Remember to reset the index variables to 0 if an illegal character is detected (and then rerun the loop).

Difficulty 6: Dealing with illegal character (symbols, letters, or anything other than floating-point number)

Solution: Similar to assignment 1. Use *if(!cin)* to detect any pathological cases,  use *cin.clear(), cin.sync()* to clear the input stream and flag, and rerun the loop.